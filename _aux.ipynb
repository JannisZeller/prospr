{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Tests\n",
    "\n",
    "This notebook contains some tests to probe the behaviour of the used operations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian-Vector-Product / Gradient Trick\n",
    "\n",
    "For example consider $\\mathbf x = (1, 2, 3) \\in \\mathbb R^3$ and \n",
    "$$\n",
    "    f: \\mathbb R^3 \\to \\mathbb R, \\ x\\mapsto x_0^3+x_1^3+x_2^3 + 2x_0x_1x_2\\, .\n",
    "$$\n",
    "Then Gradient, Hessian, and Hessian-Gradient-Product can be calculated as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: [15. 18. 31.]\n",
      "Hessian:\n",
      " [[ 6.  6.  4.]\n",
      " [ 6. 12.  2.]\n",
      " [ 4.  2. 18.]]\n",
      "Rowsums of Hessian: [16. 20. 24.]\n",
      "Hessian times Gradient Explicitly:\n",
      " [322. 368. 654.]\n",
      "Hessian times Gradient Implicitly:\n",
      " [322. 368. 654.]\n"
     ]
    }
   ],
   "source": [
    "## Testing Tape Behaviour\n",
    "x = tf.Variable([1., 2., 3.])\n",
    "with tf.GradientTape(persistent=True) as outer_tape:\n",
    "    with tf.GradientTape() as tape:\n",
    "       y = tf.reduce_sum(x ** 3.) + 2*tf.reduce_prod(x)\n",
    "    grad  = tape.gradient(y, x)\n",
    "    int_H = tf.reduce_sum(grad * tf.stop_gradient(grad))\n",
    "hess = outer_tape.jacobian(grad, x)\n",
    "hess_rowsums = outer_tape.gradient(grad, x)\n",
    "hess_x_grad = outer_tape.gradient(int_H, x)\n",
    "\n",
    "print(\"Gradient:\", grad.numpy())\n",
    "print(\"Hessian:\\n\", hess.numpy())\n",
    "print(\"Rowsums of Hessian:\", hess_rowsums.numpy())\n",
    "print(\"Hessian times Gradient Explicitly:\\n\", \n",
    "    tf.matmul([hess], tf.transpose([grad])).numpy().flatten())\n",
    "print(\"Hessian times Gradient Implicitly:\\n\",\n",
    "    hess_x_grad.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using a usual `GradientTape` one can also use a `ForwardAccumulator` which is able of directly calculating jacobina-vector-products and therefore also hessian-gradient-products (see the [docs](https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator)). Yet for doing so, we already need the gradient to pass it as `tangents` to the `ForwardAccumulator`. This is less efficient when having lots of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian-x-Gradient via. `ForwardAccumulator`_\n",
      " [322. 368. 654.]\n"
     ]
    }
   ],
   "source": [
    "with tf.autodiff.ForwardAccumulator(x, grad) as acc:\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = tf.reduce_sum(x ** 3.) + 2*tf.reduce_prod(x)\n",
    "    grad2 = tape.gradient(y, x)\n",
    "print(\"Hessian-x-Gradient via. `ForwardAccumulator`_\\n\",\n",
    "    acc.jvp(grad2).numpy())  # forward-over-backward Hessian-vector product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9da7387ac238462230b0dbd9bf3fc9372aae1b82f76d8141914412c04a1575e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
